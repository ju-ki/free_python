{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5531726674375732\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_true = [1.0, 1.5, 2.0, 1.2, 1.8]\n",
    "y_pred = [0.8, 1.5, 1.8, 1.3, 3.0]\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4944905400842203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "y_true = [100, 0, 400]\n",
    "y_pred = [200, 10, 200]\n",
    "\n",
    "rmsle = np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "print(rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_true = [100, 160, 60]\n",
    "y_pred = [80, 100, 100]\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 1]\n",
      " [2 2]]\n",
      "[[2 1]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = [1, 0, 1, 1, 0, 1, 1, 0]\n",
    "y_pred = [0, 0, 1, 1, 0, 0, 1, 1]\n",
    "\n",
    "tp = np.sum((np.array(y_true) == 1) & (np.array(y_pred) == 1))\n",
    "tn = np.sum((np.array(y_true) == 0) & (np.array(y_pred) == 0))\n",
    "fp = np.sum((np.array(y_true) == 0) & (np.array(y_pred) == 1))\n",
    "fn = np.sum((np.array(y_true) == 1) & (np.array(y_pred) == 0))\n",
    "\n",
    "confusion_matrix1 = np.array([[tp, fp],\n",
    "                             [fn, tn]])\n",
    "\n",
    "print(confusion_matrix1)\n",
    "\n",
    "\n",
    "confusion_matrix2 = confusion_matrix(y_true, y_pred)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_true = [1, 0, 1, 1, 0, 1, 1, 0]\n",
    "y_pred = [0, 0, 1, 1, 0, 0, 1, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7135581778200728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "y_true = [1, 0, 1, 1, 0, 1]\n",
    "y_prob = [0.1, 0.2, 0.8, 0.8, 0.1, 0.3]\n",
    "\n",
    "logloss = log_loss(y_true, y_prob)\n",
    "print(logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3625557672904274\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "y_true = np.array([0, 2, 1, 2, 2])\n",
    "y_pred = np.array([[0.68, 0.32, 0.00],\n",
    "                  [0.00, 0.00, 1.00],\n",
    "                  [0.60, 0.40, 0.00],\n",
    "                  [0.00, 0.00, 1.00],\n",
    "                  [0.28, 0.12, 0.60]])\n",
    "logloss = log_loss(y_true, y_pred)\n",
    "print(logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5933333333333334 0.5523809523809523 0.6250000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_true = np.array([[1, 1, 0],\n",
    "                  [1, 0, 0],\n",
    "                  [1, 1, 1],\n",
    "                  [0, 1, 1],\n",
    "                  [0, 0, 1]])\n",
    "\n",
    "y_pred = np.array([[1, 0, 1],\n",
    "                  [0, 1, 0],\n",
    "                  [1, 0, 1],\n",
    "                  [0, 0, 1],\n",
    "                  [0, 0, 1]])\n",
    "\n",
    "mean_f1 = np.mean([f1_score(y_true[i, :], y_pred[i, :]) for i in range(len(y_true))])\n",
    "\n",
    "n_class = 3\n",
    "\n",
    "marco_f1 = np.mean([f1_score(y_true[:, c], y_pred[:, c]) for c in range(n_class)])\n",
    "\n",
    "micro_f1 = f1_score(y_true.reshape(-1), y_pred.reshape(-1))\n",
    "\n",
    "print(mean_f1, marco_f1, micro_f1)\n",
    "\n",
    "mean_f1 = f1_score(y_true, y_pred,average=\"samples\")\n",
    "macro_f1 = f1_score(y_true, y_pred,average=\"macro\")\n",
    "micro_f1 = f1_score(y_true, y_pred,average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "\n",
    "def quadratic_weighted_kappa(c_matrix):\n",
    "    number = 0.0\n",
    "    denom = 0.0\n",
    "    \n",
    "    for i in range(c_matrix.shape[0]):\n",
    "        for j in range(c_matrix.shape[1]):\n",
    "            n = c_matrix.shape[0]\n",
    "            wij = ((i - j) ** 2.0)\n",
    "            oij = c_matrix[i, j]\n",
    "            eij = c_matrix[i, :].sum() * c_matrix[:, j].sum() / c_matrix.sum()\n",
    "            number += wij * oij\n",
    "            denom += wij * eij\n",
    "            \n",
    "    return 1.0 - number / denom\n",
    "\n",
    "y_true = [1, 2, 3, 4, 3]\n",
    "y_pred = [2, 2, 4, 4, 5]\n",
    "\n",
    "\n",
    "c_matrix = confusion_matrix(y_true, y_pred, labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "kappa = quadratic_weighted_kappa(c_matrix)\n",
    "print(kappa)\n",
    "\n",
    "kappa = cohen_kappa_score(y_true, y_pred, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "\n",
    "y_true = [[1, 2], [1, 2], [4], [1, 2, 3, 4], [3, 4]]\n",
    "\n",
    "y_pred = [[1, 2, 4], [4, 1, 2], [1, 4, 3], [1, 2, 3], [1, 2, 4]]\n",
    "\n",
    "def apk(y_i_true, y_i_pred):\n",
    "    assert (len(y_i_pred) <= K)\n",
    "    assert (len(np.unique(y_i_pred) == len(y_i_pred)))\n",
    "    \n",
    "    sum_precision = 0.0\n",
    "    num_hits = 0.0\n",
    "    \n",
    "    \n",
    "    for i, p in enumerate(y_i_pred):\n",
    "        if p in y_i_true:\n",
    "            num_hits += 1\n",
    "            precision = num_hits / (i + 1)\n",
    "            sum_precision += precision\n",
    "            \n",
    "    return sum_precision / min(len(y_i_true), K)\n",
    "\n",
    "def mapk(y_true, y_pred):\n",
    "    return np.mean([apk(y_i_true, y_i_pred) for y_i_true, y_i_pred in zip(y_true, y_pred)])\n",
    "\n",
    "\n",
    "print(mapk(y_true, y_pred))\n",
    "\n",
    "print(apk(y_true[0], y_pred[0]))\n",
    "print(apk(y_true[1], y_pred[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
